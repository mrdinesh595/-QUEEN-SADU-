const config = require('../config');
const { cmd, commands } = require('../command');
const { fetchJson } = require('../lib/functions');
const fs=require('fs');
const path=require('path');
const{readEnv}=require('../lib/database');
var desct = "It Search On Chatgpt Ai For What You Provided."
var needus = "*Please Give Me Words To Search On AI !*" 
var cantf  = "*Server Is Busy. Try Again Later.!*"

/*
const fetch = require('node-fetch');  // Fetch module for making HTTP requests

cmd({ on: "body" }, async (conn, mek, m, { from, body, isOwner }) => {
  try {
    // URL of the raw JSON file in GitHub repository
    const jsonUrl = 'https://raw.githubusercontent.com/Sl-nethumax/database/refs/heads/main/responses.json';

    // Fetch JSON data from the raw URL
    const response = await fetch(jsonUrl);
    
    if (!response.ok) {
      throw new Error('Failed to fetch the JSON data from GitHub.');
    }

    const responses = await response.json(); // Parse the JSON response

    // Check if AUTO_AI is enabled
    const config = await readEnv();
    
    if (config.AUTO_AI === 'true') {
      if (isOwner) return; // If the user is the owner, don't process further

      // Check if the message has a pre-defined response in the JSON file
      if (responses[body]) {
        let response = responses[body];
        await m.reply(response);
      } else {
        await m.reply("‡∂∏‡∂ß ‡∂∏‡∑ö ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂±‡∂∫‡∂ß ‡∂¥‡∑í‡∂Ω‡∑í‡∂≠‡∑î‡∂ª‡∂ö‡∑ä ‡∂±‡∑ê‡∑Ñ‡∑ê.");
      }
    }
  } catch (e) {
    console.error(e);  // Log the full error for debugging
    await m.reply(`Error: ${e.message || e}`);
  }
});
*/
//========================AI =============================

cmd({
    pattern: "ai",
    react: 'üëæ',
    desc: desct,
    category: "ai",
    use: '.chatgpt <query>',
    filename: __filename

},

async(conn, mek, m, {from, l, prefix, quoted, body, isCmd, command, args, q, isGroup, sender, senderNumber, botNumber2, botNumber, pushname, isMe, isOwner, groupMetadata, groupName, participants, groupAdmins, isBotAdmins, isAdmins, reply}) => {

    try {

        if (!q) return reply("‡∂î‡∂∂‡∂ß ‡∂Ö‡∂∫‡∑î‡∂≠‡∑î ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂±‡∂∫‡∂ö‡∑ä ‡∂Ω‡∂∂‡∑è ‡∂Ø‡∑ì‡∂∏ ‡∂Ö‡∑Ä‡∑Å‡∑ä‚Äç‡∂∫‡∂∫‡∑í. ‡∂ã‡∂Ø‡∑è: '.ai ‡∂î‡∂∫‡∑è‡∑Ä ‡∑Ñ‡∑ê‡∂Ø‡∑î‡∑Ä‡∑ö ‡∂ö‡∑Ä‡∑î‡∂Ø?'");

        // Check if the user is asking about who created the AI
        if (q.toLowerCase() === "‡∂î‡∂∫‡∑è‡∑Ä ‡∑Ñ‡∑ê‡∂Ø‡∑î‡∑Ä‡∑ö ‡∂ö‡∑Ä‡∑î‡∂Ø?" || q.toLowerCase() === "who created you?") {
            return reply("‡∂∏‡∑è‡∑Ä ‡∂±‡∑í‡∂ª‡∑ä‡∂∏‡∑è‡∂´‡∂∫ ‡∂ö‡∂ª‡∑ö NETHU-AI. ‡∂î‡∂∂‡∂ß ‡∂ö‡∑ú‡∑Ñ‡∑ú‡∂∏ ‡∑Ñ‡∑ù ‡∂ã‡∂Ø‡∑Ä‡∑ä ‡∂ö‡∂Ω ‡∑Ñ‡∑ê‡∂ö.");
        }

        // Check if the user asks "‡∂î‡∂∫‡∑è ‡∂ö‡∑Ä‡∑î‡∂Ø?"
        if (q.toLowerCase() === "‡∂î‡∂∫‡∑è ‡∂ö‡∑Ä‡∑î‡∂Ø?" || q.toLowerCase() === "who are you?") {
            return reply("‡∂∏‡∂∏ NETHU-AI. ‡∂ö‡∑ú‡∑Ñ‡∑ú‡∂∏‡∂Ø ‡∂î‡∂∂‡∂ß ‡∑É‡∑Ñ‡∂∫‡∑Ä‡∑í‡∂∫ ‡∑Ñ‡∑ê‡∂ö‡∑ä‡∂ö‡∑ö?");
        }

        // API call to fetch a response from the AI service
        let res = await fetchJson('https://hercai.onrender.com/v3/hercai?question=' + q);

        return await reply(res.reply);

    } catch (e) {
        reply("‡∂∏‡∂ß ‡∂î‡∂∂‡∑ö ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂±‡∂∫‡∂ß ‡∂ã‡∂≠‡∑ä‡∂≠‡∂ª‡∂∫‡∂ö‡∑ä ‡∑É‡∑ú‡∂∫‡∑è ‡∂ú‡∂≠ ‡∂±‡∑ú‡∑Ñ‡∑ê‡∂ö‡∑í ‡∑Ä‡∑í‡∂∫.");
        console.log(e);
    }

});

//==============================CHATGPT============================

cmd({
    pattern: "chatgpt",
    alias: ["gpt","openai","chat"],
    react: 'üëæ',
    desc: desct,
    category: "ai",
    use: '.chatgpt <query>',
    filename: __filename
},
async(conn, mek, m,{from, l, prefix, quoted, body, isCmd, command, args, q, isGroup, sender, senderNumber, botNumber2, botNumber, pushname, isMe, isOwner, groupMetadata, groupName, participants, groupAdmins, isBotAdmins, isAdmins, reply}) => {
try{
if(!q) return reply(needus)
//let res = (await fetchJson('https://hercai.onrender.com/v3/hercai?question=' + q)).response
let res = await fetchJson('https://hercai.onrender.com/v3/hercai?question='+q)

return await reply(res.reply)
} catch (e) {
reply(cantf)
console.log(e)
}
})
//==============================CHATGPT2============================

cmd({
    pattern: "chatgpt2",
    alias: ["ai2","gpt2","openai2","chat2"],
    react: 'üëæ',
    desc: desct,
    category: "ai",
    use: '.chatgpt2 <query>',
    filename: __filename
},
async(conn, mek, m,{from, l, prefix, quoted, body, isCmd, command, args, q, isGroup, sender, senderNumber, botNumber2, botNumber, pushname, isMe, isOwner, groupMetadata, groupName, participants, groupAdmins, isBotAdmins, isAdmins, reply}) => {
try{
if(!q) return reply(needus)
//let res = (await fetchJson('https://hercai.onrender.com/v3/hercai?question=' + q)).response
let res = await fetchJson('https://hercai.onrender.com/v3-32k/hercai?question='+q)

return await reply(res.reply)
} catch (e) {
reply(cantf)
console.log(e)
}
})
//==============================TURBO============================

cmd({
    pattern: "turbo",
    alias: ["ai3","gpt3","openai3","chat3"],
    react: 'üëæ',
    desc: desct,
    category: "ai",
    use: '.turbo <query>',
    filename: __filename
},
async(conn, mek, m,{from, l, prefix, quoted, body, isCmd, command, args, q, isGroup, sender, senderNumber, botNumber2, botNumber, pushname, isMe, isOwner, groupMetadata, groupName, participants, groupAdmins, isBotAdmins, isAdmins, reply}) => {
try{
if(!q) return reply(needus)
//let res = (await fetchJson('https://hercai.onrender.com/v3/hercai?question=' + q)).response
let res = await fetchJson('https://hercai.onrender.com/turbo/hercai?question='+q)

return await reply(res.reply)
} catch (e) {
reply(cantf)
console.log(e)
}
})
//==============================TURBO2============================

cmd({
    pattern: "turbo2",
    alias: ["ai4","gpt4","turbo16k","chat4"],
    react: 'üëæ',
    desc: desct,
    category: "ai",
    use: '.turbo16k <query>',
    filename: __filename
},
async(conn, mek, m,{from, l, prefix, quoted, body, isCmd, command, args, q, isGroup, sender, senderNumber, botNumber2, botNumber, pushname, isMe, isOwner, groupMetadata, groupName, participants, groupAdmins, isBotAdmins, isAdmins, reply}) => {
try{
if(!q) return reply(needus)
//let res = (await fetchJson('https://hercai.onrender.com/v3/hercai?question=' + q)).response
let res = await fetchJson('https://hercai.onrender.com/turbo-16k/hercai?question='+q)

return await reply(res.reply)
} catch (e) {
reply(cantf)
console.log(e)
}
})
//==============================GEMINI============================

cmd({
    pattern: "gemini",
    alias: ["ai5","gpt5","openai5","chat5"],
    react: 'üëæ',
    desc: desct,
    category: "ai",
    use: '.gemini <query>',
    filename: __filename
},
async(conn, mek, m,{from, l, prefix, quoted, body, isCmd, command, args, q, isGroup, sender, senderNumber, botNumber2, botNumber, pushname, isMe, isOwner, groupMetadata, groupName, participants, groupAdmins, isBotAdmins, isAdmins, reply}) => {
try{
if(!q) return reply(needus)
//let res = (await fetchJson('https://hercai.onrender.com/v3/hercai?question=' + q)).response
let res = await fetchJson('https://hercai.onrender.com/gemini/hercai?question='+q)

return await reply(res.reply)
} catch (e) {
reply(cantf)
console.log(e)
}
})


